{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "\n",
    "from \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义地图环境\n",
    "class GridEnv:\n",
    "    def __init__(self, grid_size, start, goal, obstacles):\n",
    "        self.grid_size = grid_size\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.obstacles = obstacles\n",
    "        self.state = start\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.start\n",
    "        self.done = False\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise ValueError(\"环境已结束，请重置。\")\n",
    "\n",
    "        x, y = self.state\n",
    "        if action == 0:  # 上\n",
    "            next_state = (x, y - 1)\n",
    "        elif action == 1:  # 下\n",
    "            next_state = (x, y + 1)\n",
    "        elif action == 2:  # 左\n",
    "            next_state = (x - 1, y)\n",
    "        elif action == 3:  # 右\n",
    "            next_state = (x + 1, y)\n",
    "\n",
    "        # 边界检查\n",
    "        if (next_state[0] < 0 or next_state[0] >= self.grid_size[0] or\n",
    "            next_state[1] < 0 or next_state[1] >= self.grid_size[1]):\n",
    "            next_state = self.state\n",
    "\n",
    "        # 障碍物检查\n",
    "        if next_state in self.obstacles:\n",
    "            reward = -1\n",
    "            next_state = self.state\n",
    "        elif next_state == self.goal:\n",
    "            reward = 10\n",
    "            self.done = True\n",
    "        else:\n",
    "            reward = -0.1\n",
    "\n",
    "        self.state = next_state\n",
    "        return self._get_state(), reward, self.done\n",
    "\n",
    "    def _get_state(self):\n",
    "        # 将位置状态编码为网格大小的向量，便于模型输入\n",
    "        state = np.zeros(self.grid_size).flatten()\n",
    "        idx = self.state[0] * self.grid_size[1] + self.state[1]\n",
    "        state[idx] = 1\n",
    "        return state\n",
    "\n",
    "# 定义 Actor-Critic 模型\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc_policy = nn.Linear(128, action_dim)\n",
    "        self.fc_value = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        policy_logits = self.fc_policy(x)\n",
    "        state_value = self.fc_value(x)\n",
    "        return policy_logits, state_value\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        self.eval()\n",
    "        logits, _ = self.forward(state)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        action = Categorical(probs).sample()\n",
    "        return action.item()\n",
    "\n",
    "# Worker 进程定义\n",
    "class Worker(mp.Process):\n",
    "    def __init__(self, global_model, optimizer, global_ep, global_ep_r, res_queue, env_params):\n",
    "        super(Worker, self).__init__()\n",
    "        self.g_ep, self.g_ep_r, self.res_queue = global_ep, global_ep_r, res_queue\n",
    "        self.global_model, self.optimizer = global_model, optimizer\n",
    "        self.env = GridEnv(*env_params)\n",
    "        self.local_model = ActorCritic(25, 4).to(device)\n",
    "        self.local_model.load_state_dict(self.global_model.state_dict())\n",
    "\n",
    "    def run(self):\n",
    "        while self.g_ep.value < 500:  # 假设500个episode\n",
    "            state = self.env.reset()\n",
    "            buffer_s, buffer_a, buffer_r = [], [], []\n",
    "            ep_r = 0\n",
    "            while True:\n",
    "                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "                action = self.local_model.choose_action(state_tensor)\n",
    "                next_state, reward, done = self.env.step(action)\n",
    "\n",
    "                ep_r += reward\n",
    "                buffer_s.append(state)\n",
    "                buffer_a.append(action)\n",
    "                buffer_r.append(reward)\n",
    "\n",
    "                if done:\n",
    "                    self.update_global(buffer_s, buffer_a, buffer_r, done, next_state)\n",
    "                    with self.g_ep.get_lock():\n",
    "                        self.g_ep.value += 1\n",
    "                    with self.g_ep_r.get_lock():\n",
    "                        if self.g_ep_r.value == 0.:\n",
    "                            self.g_ep_r.value = ep_r\n",
    "                        else:\n",
    "                            self.g_ep_r.value = self.g_ep_r.value * 0.99 + ep_r * 0.01\n",
    "                    self.res_queue.put(self.g_ep_r.value)\n",
    "                    break\n",
    "                state = next_state\n",
    "\n",
    "    def update_global(self, buffer_s, buffer_a, buffer_r, done, next_state):\n",
    "        if done:\n",
    "            v_s_ = 0\n",
    "        else:\n",
    "            next_state_tensor = torch.FloatTensor(next_state).unsqueeze(0).to(device)\n",
    "            _, v_s_ = self.local_model(next_state_tensor)\n",
    "            v_s_ = v_s_.item()\n",
    "\n",
    "        buffer_v_target = []\n",
    "        for r in buffer_r[::-1]:\n",
    "            v_s_ = r + 0.99 * v_s_\n",
    "            buffer_v_target.append(v_s_)\n",
    "        buffer_v_target.reverse()\n",
    "\n",
    "        loss = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        for s, a, v_t in zip(buffer_s, buffer_a, buffer_v_target):\n",
    "            s_tensor = torch.FloatTensor(s).unsqueeze(0).to(device)\n",
    "            logits, v = self.local_model(s_tensor)\n",
    "            advantage = v_t - v.item()\n",
    "\n",
    "            action_loss = -torch.log_softmax(logits, dim=-1)[0, a] * advantage\n",
    "            value_loss = F.mse_loss(v, torch.tensor(v_t).to(device))\n",
    "            loss += (action_loss + value_loss)\n",
    "\n",
    "        loss.backward()\n",
    "        for global_param, local_param in zip(self.global_model.parameters(), self.local_model.parameters()):\n",
    "            global_param._grad = local_param.grad\n",
    "        self.optimizer.step()\n",
    "        self.local_model.load_state_dict(self.global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/home/nuplan/miniconda3/envs/me5418-group10/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完成，累计奖励: [-55.10000000000025, -55.10000000000025, -55.10000000000025, -53.91993000000024, -55.10000000000025, -52.774909259070235, -55.10000000000025, -55.10000000000025, -55.10000000000025, -54.50700000000025, -53.35041339300024, -52.20516016647953, -53.931730700000244, -51.74384109933117, -51.64110856481473, -51.67569747916659, -51.21762866145448, -51.70994050437492, -51.77740268833786, -51.29488785109153, -51.25645237483993, -51.332938972580614, -51.37060958285481, -51.23690348702627, -51.01953445215601, -50.88933910763445, -51.03544571655811, -51.180091259392526, -51.0392903467986, -50.92089744333062, -50.854688468897315, -50.862141584208345, -50.869520168366265, -50.7408249666826, -50.58741671701578, -50.43554254984562, -49.96918712434716, -49.498495253103684, -49.032510300572646, -48.57118519756692, -48.12347334559124, -48.198238612135334, -48.263256226013986, -48.15662366375385, -48.03605742711631, -48.10269685284515, -48.027669884316694, -48.022393185473526, -48.04416925361879, -48.122727561082606, -47.90250028547178, -47.98247528261707, -47.9956505297909, -47.54669402449299, -47.102227084248064, -46.66220481340558, -46.58958276527153, -46.16968693761881, -45.70799006824262, -45.2479101675602, -44.7954310658846, -44.60847675522576, -44.1623919876735, -43.76376806779677, -43.3721303871188, -43.199409083247616, -43.161414992415146, -42.747800842490996, -42.70532283406609, -42.31426960572543, -41.954126909668176, -41.9195856405715, -41.515389784165784, -41.110235886324126, -40.65013352746089, -40.258632192186276, -40.05804587026441, -39.67546541156177, -39.215710757446146, -38.838553649871685, -38.39716811337297, -38.00819643223924, -37.87711446791685, -37.53734332323768, -37.200969890005304, -36.82396019110525, -36.5127205891942, -36.188593383302255, -35.871707449469234, -35.526990374974545, -35.1087204712248, -35.11563326651255, -34.789476933847425, -34.47758216450895, -34.09580634286387, -33.71784827943523, -33.40566979664088, -33.10761309867447, -32.76353696768773, -32.47690159801085, -32.11513258203074, -32.272981256210436, -31.88725144364833, -32.01937892921185, -31.821185139919727, -31.59397328852053, -31.693033555635328, -31.308103220078973, -30.92702218787818, -31.0967519659994, -30.708784446339404, -30.33369660187601, -29.953359635857247, -29.757826039498674, -29.50924777910369, -29.693155301312654, -29.448223748299526, -29.560741510816534, -29.31713409570837, -28.946962754751283, -29.06449312720377, -28.824848195931732, -28.527599713972414, -28.17432371683269, -27.88358047966436, -27.63474467486772, -27.43539722811904, -27.19804325583785, -26.87006282327947, -26.65036219504667, -26.431858573096203, -26.104539987365243, -25.84349458749159, -25.633059641616672, -25.428729045200505, -25.1394417547485, -24.936047337201014, -24.686686863829003, -24.387819995190714, -24.108941795238806, -23.90685237728642, -23.706783853513556, -23.41371601497842, -23.095578854828634, -22.829623066280348, -22.545326835617544, -22.23687356726137, -21.958504831588755, -21.703919783272866, -21.453880585440135, -21.156341779585734, -20.861778361789877, -20.601160578171978, -20.43514897239026, -20.191797482666356, -19.929879507839694, -19.785580712761295, -19.535724905633682, -19.293367656577345, -19.072433980011574, -18.85370964021146, -18.742172543809342, -18.49475081837125, -18.32780331018754, -18.109525277085666, -17.94643002431481, -17.798965724071664, -17.63897606683095, -17.53558630616264, -17.277230443101015, -17.065458138670003, -16.967803557283304, -16.77812552171047, -16.571344266493366, -16.37063082382843, -16.181924515590147, -15.980105270434247, -15.737304217729905, -15.519931175552605, -15.153064545159108, -15.36673186379708, -14.968533899707516, -14.83484856071044, -14.605500075103336, -14.475445074352303, -14.31069062360878, -14.185583717372692, -14.010727880198965, -13.696074395383006, -13.854620601396975, -13.526113651429176, -13.355852514914885, -13.187293989765735, -13.020421049868077, -12.807216839369396, -12.5961446709757, -12.410183224265943, -12.251081392023282, -12.04557057810305, -11.94311487232202, -11.7426837235988, -11.562256886362812, -11.411634317499184, -11.262517974324192, -11.11489279458095, -11.05974386663514, -10.884146427968789, -10.7063049636891, -10.655241914052208, -10.513689494911686, -10.325552599962569, -10.187297073962943, -10.050424103223314, -9.86691986219108, -9.792250663569169, -9.629328156933477, -9.446034875364143, -9.264574526610502, -9.120928781344396, -8.964719493530954, -8.893072298595644, -8.739141575609688, -8.586750159853592, -8.518882658255057, -8.368693831672507, -8.225006893355781, -8.099756824422224, -7.935759256178002, -7.821401663616222, -7.724187646980059, -7.563945770510259, -7.4053063128051555, -7.379253249677104, -7.347460717180333, -7.230986110008529, -7.1496762489084436, -7.120179486419359, -6.973977691555166, -6.852237914639614, -6.723715535493219, -6.704478380138287, -6.693433596336904, -6.665499260373535, -6.6468442677698, -6.494375825092101, -6.36943206684118, -6.228737746172769, -6.12045036871104, -6.013245865023929, -5.99211340637369, -5.846192272309953, -5.700730349586854, -5.5577230460909846, -5.541145815630075, -5.399734357473774, -5.3117370138990365, -5.233619643760046, -5.148283447322445, -5.01080061284922, -4.895692606720727, -4.83373568065352, -4.720398323846984, -4.709194340608514, -4.637102397202429, -4.505731373230405, -4.3746740594981, -4.305927318903119, -4.229868045714087, -4.154569365256946, -4.031023671604377, -3.957713434888333, -3.8851363005394495, -3.766284937534055, -3.6956220881587147, -3.6246658672771277, -3.5544192086043562, -3.4858750165183126, -3.3980162663531295, -3.3110361036895983, -3.2449257426527023, -3.1974764852261752, -3.131501720373913, -3.020186703170174, -2.909984836138472, -2.800884987777087, -2.7388761378993163, -2.630487376520323, -2.5241825027551195, -2.4189406777275684, -2.373751270950293, -2.3400137582407896, -2.2366136206583818, -2.219247484451798, -2.17605500960728, -2.1202944595112077, -2.0660915149160957, -2.016430599766935, -1.9432662937692657, -1.879833630831573, -1.7690352945232573, -1.7563449415780246, -1.6557814921622442, -1.6442236772406216, -1.5467814404682154, -1.536313626063533, -1.4479504898028979, -1.4564709849048687, -1.36890627505582, -1.3032172123052619, -1.3131850401822092, -1.2390531897803871, -1.2796626578825832, -1.2098660313037575, -1.15376737099072, -1.1652296972808127, -1.0965774003080047, -1.0176116263049246, -0.9504355100418754, -0.8659311549414567, -0.8282718433920421, -0.7449891249581216, -0.6805392337085404, -0.629733841371455, -0.5664365029577404, -0.47077213792816297, -0.4900644165488812, -0.4001637723833924, -0.33916213465955847, -0.25277051331296285, -0.16724280817983325, -0.11957038009803492, -0.07437467629705456, -0.012630929534084033, 0.024495379761256875, 0.03725042596364435, 0.04987792170400794, 0.06237914248696791, 0.15175535106209823, 0.16323779755147727, 0.19060541957596253, 0.2716993653802029, 0.31998237172640087, 0.36778254800913684, 0.3871047225290455, 0.3962336753037551, 0.46927133855071756, 0.5225786251652104, 0.5663528389135583, 0.5736893105244226, 0.6589524174191783, 0.7433628932449865, 0.8259292643125365, 0.8466699716694112, 0.905203271952717, 0.9631512392331898, 1.020519726840858, 1.0713145295724493, 1.1276013842767247, 1.243492116729618, 1.243492116729618, 1.2570571955623218, 1.2734866236066986, 1.3167517573706318, 1.3705842397969255, 1.3858783973989561, 1.4330196134249664, 1.4236894172907169, 1.4144525231178098, 1.4613079978866317, 1.5026949179077653, 1.5436679687286876, 1.5842312890414008, 1.6003889761509869, 1.640385086389477, 1.7069812355255822, 1.7579114231703266, 1.7963323089386234, 1.8103689858492371, 1.8242652959907448, 1.8380226430308373, 1.875642416600529, 1.8888859924345238, 1.8529971325101786, 1.902467161185077, 1.8664424895732263, 1.927778064677494, 1.9275002840307192, 1.928225281190412, 1.876943028378508, 1.890173598094723, 1.9412718621137757, 1.953859143492638, 1.9483205520577116, 1.9668373465371345, 1.9671689730717632, 2.0144972833410457, 2.0613523105076355, 2.096738787402559, 2.0897713995285336, 2.0828736855332486, 2.0760449486779162, 2.117284499191137, 2.1101116541992258, 2.1280105376572336, 2.1207304322806615, 2.137523127957855, 2.1481478966782763, 2.140666417711494, 2.137259753534379, 2.153887155999035, 2.150348284439045, 2.146844801594655, 2.1433763535787085, 2.0929425900429215, 2.0430131641424922, 2.0205830325010674, 2.018377202176057, 2.0161934301542965, 2.0430314958527536, 2.111601180894226, 2.1794851690852837, 2.132690317394431, 2.129363414220487, 2.155069780078282, 2.1475190822774994, 2.0500438914547243, 2.0045434525401773, 1.9594980180147756, 1.914903037834628, 1.8867540074562816, 1.842886467381719, 1.808457602707902, 1.765373026680823, 1.7257192964140147, 1.7754621034498745, 1.7327074824153759, 1.753380407591222, 1.7538466035153097, 1.8033081374801565, 1.852275056105355, 1.9007523055443014, 1.9377447824888585, 1.9563673346639698, 1.9318036613173302, 1.907485624704157, 1.9554107684571154, 2.002856660772544, 2.020828094164819, 2.0676198132231707, 2.0799436150909387, 2.0341441789400294, 2.034802737150629, 2.018454709779123, 2.0312701626813316, 2.0149574610545185, 2.0278078864439735, 2.074529807579534, 2.0577845095037386, 2.0412066644087012, 2.0247945977646142, 2.022546651786968, 2.0353211852690984, 2.0479679734164074, 2.0314882936822434, 1.9861734107454212, 1.970311676637967, 1.9436085598715873, 2.0071724742728714, 2.070100749530143, 2.0673997420348416, 2.0647257446144933, 2.0190784871683483, 2.065887702296665, 2.1979065370209616, 2.1322288252736983, 2.170927471650752, 2.1532181969342443, 2.126686014964902, 2.100419154815253, 1.9504149632671002, 1.9259108136344292, 1.901651705498085, 1.8576351884431042, 1.8930588365586731, 1.9281282481930864, 1.8838469657111556, 1.932008496054044, 1.9456884110935035, 1.9212315269825686, 1.897019211712743, 1.9660490195956155, 2.034388529399659, 2.0400446441056626, 2.086644197664606, 2.07577775568796, 2.122019978131081, 2.1187997783497705, 2.21195566276061, 2.1656117805662727, 2.184836106133004, 2.195987745071674, 2.1840278676209572, 2.2251875889447477, 2.2359357130553, 2.246576355924747, 2.2571105923654997, 2.2675394864418448, 2.2198640915774264, 2.2326654506616523, 2.245338796155036, 2.2558854081934854, 2.2663265541115503, 2.253663288570435, 2.241126655684731, 2.220715389127884]\n"
     ]
    }
   ],
   "source": [
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    env_params = ((5, 5), (0, 0), (4, 4), [(1, 1), (2, 2), (3, 3)])\n",
    "    global_model = ActorCritic(25, 4).to(device)\n",
    "    global_model.share_memory()\n",
    "    optimizer = optim.Adam(global_model.parameters(), lr=0.001)\n",
    "    global_ep, global_ep_r, res_queue = mp.Value('i', 0), mp.Value('d', 0.), mp.Queue()\n",
    "\n",
    "    workers = [Worker(global_model, optimizer, global_ep, global_ep_r, res_queue, env_params) for _ in range(mp.cpu_count())]\n",
    "    [w.start() for w in workers]\n",
    "    [w.join() for w in workers]\n",
    "\n",
    "    rewards = []\n",
    "    while not res_queue.empty():\n",
    "        rewards.append(res_queue.get())\n",
    "    print(\"训练完成，累计奖励:\", rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
